---
title: "Prediction Intervals in Meta-Analysis"
author: "Fernando E. Miguez"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prediction Intervals in Meta-Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 5)
library(knitr)
library(lme4)
library(MCMCglmm)
library(predintma)
library(ggplot2)
```

# Prediction

The topic of prediction has gained considerable attention in the field of statistics and meta-analysis is no exception. Perhaps the most important practical benefit of a prediciton interval in meta-analysis is that it encapsulates information about the between-trial variability and it complements information about the point estimate. In contrast, the magnitude of the between-trial variance is difficult to interpret in isolation and the inability to capture the between-trial variance has been a topic of intense debate. When the estimate is zero (or close) the argument is that a "fixed" model is more appropriate, but the interpretation and usefulness of a prediction interval in this case is questionable. The "random-effects" model is assumed to always be the "correct" model, but not every dataset supports this type of model. Providing prediciton intervals in meta-analysis relfects a more accurate representation about whether the drug, treatment or intervention will be effective in future environments or for other experimental units not in our sample.

## What is a prediction interval?

Let's define it:

An interval that will contain a future observation (i.e. not part of our sample) with a given level of miscoverage (say 5 or 10%), given our observed data.

Very wide intervals have a high probability of containing the future observation but are likely to be impractically wide for decision making. Intervals that are too narrow and do not have nominal coverage give us an illusion of precision and certainty which might not hold true in the long run.

A prediction interval (https://en.wikipedia.org/wiki/Prediction_interval) is not a new idea and it goes back to the tradition of Gosset, Fisher and Neyman (Shafer and Vovk, 2008). 

### Mathematical definition

Given a sample ($X_1, X_2, X_3, ..., X_n$) we want an interval that will contain $X_{n+1}$ with probability ($1 - \alpha$, where $\alpha \in (0,1)$). The level of miscoverage ($\alpha$) is typically 0.05 or 0.10. It is common to suppose that $X$ needs to meet the assumption of identically and indepenednently distributed (iid) and Gaussian, but this can be relaxed. 

# Classes supported

There is substantial material on this topic here: https://femiguez.github.io/paf/

Classes supported:

* 'numeric': **pred_int_tdist** and **pred_int_conformal**
* 'data.frame': **pred_int_metafor** and **pred_int_mcg_ntrial**
* 'MCMCglmm': **pred_int_mcg_tdist** (method 'tdist'), 
              **pred_int** (method = 'mcmc'),
              **pred_int** (method = 'simulate'),
              **pred_int** (merthod = 'predict')
* 'lmerMod': **pred_int** (method = 'tdist'),
             **pred_int** (method = 'boot'),
             **pred_int** (method = 'tdist2')
             
All of these methods can be accessed through the interface 'pred_int'

## A variable from a single distribution

If we want a prediction interval for a new observation ($Y_{n+1}$) after a sample of 
$Y_1,Y_2,Y_3,...,Y_n$ we can use the following functions.

```{r predint-numeric-class}
set.seed(101)
y <- rnorm(50)
## Using the t-distribution
pdi.t <- pred_int_tdist(y)
## or pdi.t <- pred_int(y)
## Using conformal inference
pdi.c <- pred_int_conformal(y)
## or pdi.c <- pred_int(y, method = "conformal")
## Compare this with quantiles
y.quant <- quantile(y, probs = c(0.5, 0.025, 0.975))
```

```{r pred-int-numeric-class-table}
kable(data.frame(method = c("tdist","conformal","quantile"),
                 rbind(pdi.t, pdi.c, y.quant)), digits = c(0,2,2,2),
      row.names = FALSE)
```

## Defining a Random-Effects Meta-analysis model

Random effects models are a way of incorporating the effect of 'trial' but with an imposed distribution. Commonly it is assumed that they are normally distributed but other options are possible.

$$
y_{ij} = \mu + \theta_i + e_{ij} 
$$

## A data frame with the proper structure

If we have a data set with the proper structure with a response variable a 'trial' variable and 'reps' within trials we can use the functions that work with data.frames

Let's first visualize the data
```{r soyrs}
data(soyrs)
soyrs.s <- tsum(soyrs, var.names = c("lrr", "Trial_ID"))

ggplot(data = soyrs.s, aes(x = m, y = id)) + 
  geom_point() + xlab("log RR") + ylab("ID") +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) + 
  geom_vline(xintercept = 0)
```

Now we can calculate prediction intervals

```{r soyrs-pdi}
pdi.mf <- pred_int(soyrs, method = "metafor", var.names = c("TRT1_Yld","TRT2_Yld","Trial_ID"))
pdi.mcg <- pred_int_mcg_ntrial(lrr ~ Trial_ID, data = soyrs)
pdi.t.df <- pred_int_tdist_df(soyrs, var.names = c("lrr", "Trial_ID"))
```

Alternatively, we can fit a model first using 'lme4' and then calcualte prediction intervals.

```{r soyrs-lmer}
soy.lmm <- lmer(lrr ~ 1 + (1|Trial_ID), data = soyrs)
pdi.lm1 <- pred_int(soy.lmm, method = "tdist")
pdi.lm2 <- pred_int(soy.lmm, method = "boot")
pdi.lm3 <- pred_int(soy.lmm, method = "tdist2")
```

It is also possible to change the method used for degrees of freedom.

```{r soyrs-lmer-degfr}
pdi.lm4 <- pred_int(soy.lmm, method = "tdist", degfr = "kr")
pdi.lm5 <- pred_int(soy.lmm, method = "tdist", degfr = "zdist") ## or 'Inf'
```

Now I implemented the sub-sampling method for conformal prediction, which in this case, is distribution-free.

```{r conformal-trial-means}
pdi.cf.df <- pred_int_conformal_df(soyrs, var.names = c("lrr","Trial_ID"), s.size = 3)
```

Let's display the data for the different methods.

```{r comb-pi-soyrs, echo = FALSE}
methods <- c("metafor", "mcg-ntrial","lmer-tdist","lmer-boot","lmer-tdist2",
             "lmer-tdist-kr","lmer-tdist-inf","conformal","tdist-df")
cpdi <- data.frame(method = methods, 
                   rbind(pdi.mf,pdi.mcg,pdi.lm1,pdi.lm2,pdi.lm3,
                         pdi.lm4,pdi.lm5,pdi.cf.df,pdi.t.df))
kable(cpdi)
ggplot(data = cpdi, aes(x = fit, y = method)) +
  geom_point() + 
  geom_errorbarh(aes(xmin = lwr, xmax = upr), height = 0.5)
```
## Looking at a 'large' dataset

This is an example where a foliar fungicide was applied.

```{r mzfg}
data(mzfg)
## Remove one trial with just one rep
mzfg <- subset(mzfg, Trial_ID != "ST2007236A")
mzfg.s <- tsum(mzfg, var.names = c("lrr","Trial_ID"))

ggplot(data = mzfg.s, aes(x = m, y = id)) + 
  geom_point() + 
  geom_errorbarh(aes(xmin = lb, xmax = ub)) + 
  geom_vline(aes(xintercept = 0))
```

## Calculating prediction intervals 

```{r mzfg-pdi}
pdi.mf <- pred_int(mzfg, method = "metafor", var.names = c("TRT_Yld","CTR_Yld","Trial_ID"))
pdi.mcg <- pred_int(formula = lrr ~ Trial_ID, x = mzfg, method = "ntrial")
pdi.t.df <- pred_int_tdist_df(mzfg, var.names = c("lrr", "Trial_ID"))
```

```{r mzfg-lmer}
mz.lmm <- lmer(lrr ~ 1 + (1|Trial_ID), data = mzfg)
pdi.lm1 <- pred_int(mz.lmm, method = "tdist")
pdi.lm2 <- pred_int(mz.lmm, method = "boot")
pdi.lm3 <- pred_int(mz.lmm, method = "tdist2")
```

```{r mzfg-lmer-degfr}
pdi.lm4 <- pred_int(mz.lmm, method = "tdist", degfr = "kr")
pdi.lm5 <- pred_int(mz.lmm, method = "tdist", degfr = "zdist") ## or 'Inf'
pdi.cf.df <- pred_int_conformal_df(mzfg, var.names = c("lrr","Trial_ID"), s.size = 3)
```

```{r comb-pi-mzfg, echo = FALSE}
methods <- c("metafor", "mcg-ntrial","tdist-df","lmer-tdist","lmer-boot","lmer-tdist2",
             "lmer-tdist-kr","lmer-tdist-inf","conformal")
cpdi <- data.frame(method = methods, 
                   rbind(pdi.mf,pdi.mcg,pdi.t.df, 
                         pdi.lm1,pdi.lm2,pdi.lm3,
                         pdi.lm4,pdi.lm5,pdi.cf.df))
kable(cpdi)
ggplot(data = cpdi, aes(x = fit, y = method)) +
  geom_point() + 
  geom_errorbarh(aes(xmin = lwr, xmax = upr), height = 0.5)
```


## Comparing methods for a dataset which has a between-trial variance equal to zero

For this example I will use 90% prediction intervals as they are more stable than the 
typical 95%.

There are many models here that solve the problem in different ways. The conformal prediction interval has some advantages and disadvantages:

1. It does not make assumptions about the underlying distribution ('distribution-free')
2. It does not seem to work well for small sample sizes (n < 25)

Because it does not make assumptions about an underlying model, the interval is wider, which makes sense. For small sample sizes it is not possible to construct a proper interval because the bounds end up being the upper and lower values of the sample ('minimum and maximum').

```{r soysff}
data(soysff)
## Comparing methods
pdi.mf <- pred_int(soysff, method = "metafor", level = 0.90,
                   var.names = c("TRT_Yld","CTR_Yld","Trial_ID"))
pdi.mcg <- pred_int(formula = lrr ~ Trial_ID, x = soysff, 
                    method = "ntrial", level = 0.90)
pdi.t.df <- pred_int_tdist_df(soysff, level = 0.90,
                              var.names = c("lrr", "Trial_ID"))
soy.lmm <- lmer(lrr ~ 1 + (1|Trial_ID), data = soysff)
pdi.lm1 <- pred_int(soy.lmm, method = "tdist", level = 0.90)
pdi.lm2 <- pred_int(soy.lmm, method = "boot", level = 0.90)
pdi.lm3 <- pred_int(soy.lmm, method = "tdist2", level = 0.90)
pdi.lm4 <- pred_int(soy.lmm, method = "tdist", degfr = "kr", level = 0.90)
pdi.lm5 <- pred_int(soy.lmm, method = "tdist", degfr = "zdist", level = 0.90) ## or 'Inf'
## Bayesian methods
prior1 <- list(R = list(V = 1, nu = 0.001), G = list(G1=list(V = 1, nu = 0.001)))
soy.mcg <- MCMCglmm(lrr ~ 1, random = ~Trial_ID, data = soysff,
                    prior = prior1, pr = TRUE, verbose = FALSE)
pdi.mcg1 <- pred_int(soy.mcg, method = "simulate", level = 0.90)
methods <- c("metafor", "mcg-ntrial","lmer-tdist","lmer-boot","lmer-tdist2",
             "lmer-tdist-kr","lmer-tdist-inf","conformal","mcg-simulate",
             "tdist-df")
cpdi <- data.frame(method = methods, 
                   rbind(pdi.mf,pdi.mcg,pdi.lm1,pdi.lm2,pdi.lm3,pdi.lm4,pdi.lm5,
                         pdi.cf.df,pdi.mcg1,pdi.t.df))
kable(cpdi)
ggplot(data = cpdi, aes(x = fit, y = method)) +
  geom_point() + 
  geom_errorbarh(aes(xmin = lwr, xmax = upr), height = 0.5)
```

# Related R packages

Basically anything that starts with [pred]

* predictionInterval
* prediction
* forecast
* conformalInferernce (https://github.com/ryantibs/conformal)

# TODO

* Implement new ideas, nothing seems to be working...

# References

* Shafer and Vovk (2008). "A Tutorial on Conformal Prediction". Journal of Machine Learning Research 9 (2008) 371-421. 

* Lei et al. "Distribution-Free Predictive Inference for Regression". https://arxiv.org/abs/1604.04173

* Dunn and Wasserman (2018) "Distribution-Free Prediction Sets with Random Effects". https://arxiv.org/abs/1809.07441